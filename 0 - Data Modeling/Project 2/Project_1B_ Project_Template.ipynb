{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2\n",
      "['/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-15-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-22-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-09-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-18-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-04-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-01-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-27-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-10-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-20-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-17-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-06-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-03-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-28-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-12-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-25-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-26-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-11-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-14-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-23-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-08-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-19-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-05-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-02-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-29-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-13-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-24-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-21-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-16-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-07-events.csv', '/Users/erich/Documents/Personal/Courses/Udacity/Data Engineer - Nanodegree/0 - Data Modeling/Project 2/event_data/2018-11-30-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# joining the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "# print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the new csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Generating Keyspace and modeling tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    cluster = Cluster()\n",
    "    \n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    create keyspace if not exists udacity\n",
    "    with replication = \n",
    "    {'class' : 'SimpleStrategy', 'replication_factor' : 1}\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries list\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Table creation and data insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sessions_history table\n",
    "For this table, the columns \"session_id\" and \"item_in_session\", were chosen to be part of a composite key because the query uses \"user_id\" and \"session_id\" as filters in the query \"where\" clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create statement to generate the table for the respective query.\n",
    "\n",
    "query = \"create table if not exists sessions_history \"\n",
    "query = query + \"(session_id int, item_in_session int, artist text, song text, song_length float, primary key(session_id, item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Loading data from the .csv file to the table.\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"insert into sessions_history (session_id, item_in_session, artist, song, song_length)\"\n",
    "        query = query + \"values (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                             song  song_length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)   495.307312"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select statement to get the 1st query results: Artist Name, Song and Song Length by a given SessionId and ItemInSession.\n",
    "query1 = \"\"\"\n",
    "    select\\\n",
    "        artist\\\n",
    "        ,song\\\n",
    "        ,song_length\\\n",
    "    from sessions_history\\\n",
    "    where\\\n",
    "        session_id = 338\\\n",
    "    and item_in_session = 4\\\n",
    "        \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "lst = []\n",
    "\n",
    "for row in rows:\n",
    "    lst.extend([[row.artist, row.song, row.song_length]])\n",
    "\n",
    "pd.DataFrame(lst, columns = ['artist', 'song', 'song_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Table creation and data insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### users_activity table\n",
    "For this table, the columns \"user_id\" and \"session_id\", were chosen to be part of a composite partition key because of two main points:\n",
    "- the query uses \"user_id\" and \"session_id\" as filters in the query \"where\" clause;\n",
    "- the data in the table will be distributed by session and users in different nodes on Cassandra, which improves the overall query performance.\n",
    "\n",
    "The \"item_in_session\", is being used as a clustering key not only to make a better unique key, it will sort the data while querying (it will sort the \"song\" column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create statement to generate the table for the respective query.\n",
    "\n",
    "query = \"create table if not exists users_activity \"\n",
    "query = query + \"(user_id int, session_id int, item_in_session int, artist text, song text,\\\n",
    "                     user_first_name text, user_last_name text, PRIMARY KEY ( (user_id, session_id), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data from the .csv file to the table.\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"insert into users_activity (user_id, session_id, item_in_session, artist, song, user_first_name, user_last_name)\"\n",
    "        query = query + \"values (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user_first_name</th>\n",
       "      <th>user_last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                               song  \\\n",
       "0   Down To The Bone                                 Keep On Keepin' On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "  user_first_name user_last_name  \n",
       "0          Sylvie           Cruz  \n",
       "1          Sylvie           Cruz  \n",
       "2          Sylvie           Cruz  \n",
       "3          Sylvie           Cruz  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select statement to get the 2nd query results: Artist Name, Song Name, User First and Last Names by a given userId and SessionId.\n",
    "\n",
    "query2 = \"\"\"\n",
    "    select\\\n",
    "        artist\\\n",
    "        ,song\\\n",
    "        ,user_first_name\\\n",
    "        ,user_last_name\\\n",
    "    from users_activity\\\n",
    "    where\\\n",
    "        user_id = 10\\\n",
    "    and session_id = 182\\\n",
    "        \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "lst = []\n",
    "\n",
    "for row in rows:\n",
    "    lst.extend([[row.artist, row.song, row.user_first_name, row.user_last_name]])\n",
    "\n",
    "pd.DataFrame(lst, columns = ['artist', 'song', 'user_first_name', 'user_last_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Table creation and data insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### song_history table\n",
    "For this table, the columns \"song\" and \"user_id\", were chosen to be part of a composite key because they are used as filters in the query \"where\" clause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create statement to generate the table for the respective query.\n",
    "\n",
    "query = \"create table if not exists song_history \"\n",
    "query = query + \"(song text, user_id int, user_first_name text, user_last_name text, primary key(song, user_id))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data from the .csv file to the table.\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"insert into song_history (song, user_id, user_first_name, user_last_name)\"\n",
    "        query = query + \"values (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_first_name</th>\n",
       "      <th>user_last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_first_name user_last_name\n",
       "0      Jacqueline          Lynch\n",
       "1           Tegan         Levine\n",
       "2            Sara        Johnson"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select statement to get the 3rd query results: User First and Last Names by a given song\n",
    "\n",
    "query2 = \"\"\"\n",
    "    select\\\n",
    "        user_first_name\\\n",
    "        ,user_last_name\\\n",
    "    from song_history\\\n",
    "    where\\\n",
    "        song = 'All Hands Against His Own' \\\n",
    "        \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "lst = []\n",
    "\n",
    "for row in rows:\n",
    "    lst.extend([[row.user_first_name, row.user_last_name]])\n",
    "\n",
    "pd.DataFrame(lst, columns = ['user_first_name', 'user_last_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x10e786460>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"drop table if exists song_history\")\n",
    "session.execute(\"drop table if exists users_activity\")\n",
    "session.execute(\"drop table if exists sessions_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
