{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "# 2) instantiate a Spark session \n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "# 4) create a view to use with your SQL queries\n",
    "# 5) write code to answer the quiz questions \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/18 11:30:21 WARN Utils: Your hostname, Erichs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.15.5 instead (on interface en0)\n",
      "22/04/18 11:30:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/18 11:30:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/18 11:30:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Spark Exercises 2') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Showaddywaddy', auth='Logged In', firstName='Kenneth', gender='M', itemInSession=112, lastName='Matthews', length=232.93342, level='paid', location='Charlotte-Concord-Gastonia, NC-SC', method='PUT', page='NextSong', registration=1509380319284, sessionId=5132, song='Christmas Tears Will Fall', status=200, ts=1513720872284, userAgent='\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='1046')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|Submit Downgrade|\n",
      "|       Downgrade|\n",
      "|          Logout|\n",
      "|   Save Settings|\n",
      "|        Settings|\n",
      "|        NextSong|\n",
      "|         Upgrade|\n",
      "|           Error|\n",
      "|  Submit Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    select\n",
    "        a.page\n",
    "    from (\n",
    "        select distinct\n",
    "            page\n",
    "        from user_log_table\n",
    "        ) a\n",
    "    left join (\n",
    "                select distinct\n",
    "                    page\n",
    "                from user_log_table\n",
    "                where\n",
    "                    userId = \"\"\n",
    "            ) b\n",
    "    on  a.page = b.page\n",
    "    where\n",
    "        b.page is null\n",
    "    '''\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?\n",
    "\n",
    "I might prefer to use SQL because I'm more skilled and used to SQL syntaxes and I could easily share the code with other analysts with more familiarity with SQL.\n",
    "\n",
    "I think I would might prefer data frames over SQL because the control I would have over data, like split my queries in more steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|gender|qty|\n",
      "+------+---+\n",
      "|     F|462|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "\n",
    "spark.sql('''\n",
    "    select\n",
    "        gender\n",
    "        ,count(distinct userId) as qty\n",
    "    from user_log_table\n",
    "    where\n",
    "        gender = \"F\"\n",
    "    group by\n",
    "        gender\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|  artist|qty|\n",
      "+--------+---+\n",
      "|Coldplay| 83|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "\n",
    "spark.sql('''\n",
    "    select\n",
    "        artist\n",
    "        ,count(artist) as qty\n",
    "    from user_log_table\n",
    "    group by\n",
    "        artist\n",
    "    order by\n",
    "        qty desc\n",
    "    limit 1 \n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   avg(total_qty)|\n",
      "+-----------------+\n",
      "|6.898347107438017|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "\n",
    "home_totals = spark.sql('''\n",
    "    with is_home as (\n",
    "        select\n",
    "            userId\n",
    "            ,page\n",
    "            ,ts\n",
    "            ,case\n",
    "                when page = 'Home'\n",
    "                    then 1\n",
    "                    else 0\n",
    "            end as ishome \n",
    "        from user_log_table \n",
    "        where\n",
    "            (page = 'NextSong') or (page = 'Home')\n",
    "    )\n",
    "\n",
    "    select\n",
    "        *\n",
    "        ,sum(ishome) over(partition by userId order by ts desc rows between unbounded preceding and current row) as window_qty\n",
    "    from is_home\n",
    "            ''')\n",
    "\n",
    "home_totals.createOrReplaceTempView('tmp_window_qty')\n",
    "\n",
    "spark.sql('''\n",
    "    select\n",
    "        avg(total_qty)\n",
    "    from (\n",
    "        select\n",
    "            count(*) as total_qty\n",
    "        from tmp_window_qty\n",
    "        group by\n",
    "            userID\n",
    "            ,window_qty\n",
    "            ,page\n",
    "        having page = 'NextSong') as count_results'''\n",
    "    ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
